{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Intro/Concept","text":""},{"location":"#introconcept","title":"Intro/Concept","text":""},{"location":"#data-mirror-fragmented-projections-of-oneself","title":"Data Mirror: Fragmented Projections of Oneself","text":"<p>Data Mirror is an interactive spatial-audio installation that transforms collective presence into evolving sound and image, showing how shared spaces, and the people within them, continuously reshape one another.  </p>"},{"location":"#concept-overview","title":"Concept Overview","text":"<p>Data Mirror is an immersive spatial-audio and visual installation that places participants inside a reactive matrix-like environment driven by movement, proximity, and sonic interaction. A multistem musical composition plays through a spatial audio array, while visuals projected across the front wall reveal the system\u2019s internal \u201cdata world\u201d, a 3D space containing matrix-inspired effects, a stylized humanoid avatar, and a virtual representation of the speaker array.  </p> <p> Placeholder for concept illustration or sketch.</p> <p>Participants can manipulate sound using a Nulea M512 Wireless Trackball Mouse, which controls real-time spatialization within Unity. They can cycle through several stem combinations (drums, bass, harmony, melody) and control how those stems are spatially mirrored through different panning patterns. Stem loops come from eight pre-built musical sets created in Ableton, and these sets progress throughout the installation.  </p> <p>An Intel RealSense depth camera analyzes crowd movement and estimates a real-time center of mass. This position data modulates the global tempo. As users group together or spread apart, the music subtly shifts, reinforcing the idea that the audience, the environment, and the composition form a shared, responsive ecosystem.  </p>"},{"location":"#motivation-and-inspiration","title":"Motivation and Inspiration","text":"<p> Visual inspiration from The Matrix universe.</p> <p> Dolby Atmos, spatial panning, or object-based audio in Dolby Atmos Renderer.</p> <p>Our motivation for creating Data Mirror grew from several intersecting influences that shaped both the aesthetics and the technical design of the installation. We were inspired by The Matrix, particularly its visual language and its exploration of digital embodiment, perception, and identity. We were also motivated by Dolby Atmos, especially its object-based spatial panning and mirrored-panning techniques, which shaped how we approached sound as a movable, expressive entity within space.  </p> <p>Alongside these inspirations, our earlier work with spatial panning via OSC naturally evolved into a unified concept. These combined ideas shaped Data Mirror into an environment that reflects how people interact with digital systems and how their presence continuously transforms sound and image in real time.  </p>"},{"location":"#goals-and-learning-outcomes","title":"Goals and Learning Outcomes","text":""},{"location":"#audience-goals","title":"Audience Goals","text":"<ul> <li>Feel empowered and challenged by controlling spatial audio that responds to their actions.  </li> <li>Understand how collective movement alters the sonic and visual environment, even when one person believes they are in control.  </li> <li>Experience sound as a malleable and reactive substance rather than a fixed playback.  </li> </ul>"},{"location":"#creator-learning-goals","title":"Creator Learning Goals","text":"<ul> <li>Develop a portable and repeatable workflow for multichannel spatial installations.  </li> <li>Gain a deeper understanding of IEM spatialization, OSC routing, and Unity to DAW communication.  </li> <li>Prototype interaction models that may extend into future VR and MR spatial-music research.  </li> </ul>"},{"location":"#role-of-interactivity-and-media","title":"Role of Interactivity and Media","text":"<p>Interactivity is central to the meaning of Data Mirror: - Sound: Stems move based on user input and spatial mapping, creating a strong sense of agency. - Visuals: Matrix-style shaders, reactive color fields, and a humanoid data avatar reflect participant influence. - Shared presence: Crowd movement shapes global musical parameters, demonstrating how individual and collective behaviors influence the system. - Embodiment: Participants see and hear themselves reflected in fragmented, stylized forms that respond to their motion.  </p>"},{"location":"bpdistribution/","title":"BPDistribution","text":"The Python script implements a real-time computer vision system to track people in a video feed and analyze their horizontal distribution. It then sends this distribution data as Open Sound Control (OSC) messages to Max for Live for sound control.  1. Overall Purpose   The script takes video input from a specified camera, uses background subtraction to isolate moving objects (assumed to be people), tracks these objects over time, and calculates the following metrics for the detected crowd:   1. Count: The number of stable, currently tracked people.   2. Average X: The horizontal center-of-mass of the crowd, normalized from 0.0 (far left) to 1.0 (far right).   3. Concentration: A measure of how tightly clustered the people are horizontally, ranging from 0.0 (maximally spread) to 1.0 (maximally clustered).  2. Dependencies and Setup   - cv2 (OpenCV): video capture and computer vision processing.   - pythonosc.udp_client: send OSC messages over the network.   - numpy: numerical operations.  3. Main Tracking and OSC Logic    Initialization   1. OSC Client: udp_Client.SimpleUDPClient is initialized to send messages to the specified IP and port   2. Video Capture: cv2.VideoCapture   3. Background Subtraction: cv2.createBackgroundSubtractorMOG2 learns the stationary background and outputs a mask showing only moving foreground objects.   4. Tracking State: tracks is used to store the state of currently tracked people (position, size, last time seen, number of hits).  Frame Processing (Computer Vision)   1. Noise Reduction: A Gaussian blur is applied to the frame before background subtraction.   2. Morphological Operations: The foreground mask is cleaned using Opening (removes small noise) and Closing (fills small holes).   3. Dilation: The mask is slightly dilated to merge adjacent, broken-up blobs into single detections.   4. Thresholding: A final binary threshold is applied to ensure the mask consists only of black and white pixels   5. Contour Finding: cv2.findContours finds distinct shapes in the mask. Those smaller than args.min_area are discarded.  Tracking   The script implements a simple tracking algorithm based on the horizontal center of each detection.   1. Matching: Each new detection is compared to existing active tracks. It finds the nearest track based on the x-coordinate distance. A match is confirmed if the distance is less than 1/6 of the frame width (w / match_dist_fraction).   2. Updating: If a match is found, the track\u2019s position is updated, and its last_seen time and hits count are incremented.   3. New Tracks: If a detection cannot be matched to a nearby existing track, a new track ID is assigned.   4. Aging Out: Tracks that have not been seen (detected) for longer than args.hold seconds are removed from the system.  OSC Message Sending   OSC messages are sent at the rate defined by args.fps.   1. Active Tracks Filtering: Only tracks that have been seen recently (last_seen within args.hold) AND have been stable (hits &gt;= args.persist) are considered active tracks for distribution analysis.   2. Calculations:   - Normalized X: The horizontal center (cx) of each active track is normalized to the frame width (w) to get a value between 0.0 and 1.0.   - Average X (\u03bcx): Calculated as the mean of all normalized X-positions.   - Concentration: Calculated from the standard deviation (\u03c3x) of the normalized X-positions:    Concentration = max(0.0, 1.0 \u2212 min(\u03c3x / 0.5, 1.0))  - A low \u03c3x (people clustered) results in a high concentration score (close to 1.0).   - A high \u03c3x (people spread out) results in a low concentration score (close to 0.0).    3. Sending Messages: The following three OSC messages are sent:   - /people/count: The number of active people   - /people/avgx: The average normalized X-position (center of crowd).   - /people/concentration: The calculated concentration value.  Visualization   If the \u2014show argument is used, a debug window is displayed showing:   - Green rectangles around the current frame\u2019s detections.   - Circles marking the center of each track.   - Blue circles indicate stable tracks (hits &gt;= persist).   - Red circles indicate new/unstable tracks.   - The opacity of the track circle fades as its last_seen time approaches the args.hold limit.  Cleanup   When the script exits (by pressing \u2018q' in the display window), the camera is released, and all OpenCV windows are closed."},{"location":"final-installation/","title":"Final Installation","text":""},{"location":"final-installation/#location","title":"Location","text":"<p>Underground Atlanta</p> <p>Placeholder for venue photo [INSERT: Photo of Underground Atlanta installation area]</p>"},{"location":"final-installation/#installation-setup","title":"Installation Setup","text":""},{"location":"final-installation/#physical-layout","title":"Physical Layout","text":"<ul> <li>Speaker Array: </li> <li>QSC K10.2 units arranged in a perimeter arc (floor + head level)  </li> <li>Two elevated QSC K10.2s at the front for height cues  </li> <li>Neumann KH120 used for clarity and spatial detail  </li> <li> <p>Alto Professional TS18C Subwoofer centrally placed  </p> </li> <li> <p>Control Station: </p> </li> <li>MacBook Pro 14\" running Unity + OSC  </li> <li>Nulea M512 Wireless Trackball Mouse  </li> <li> <p>Midas M32 serving as mixer and audio interface  </p> </li> <li> <p>Visual System: </p> </li> <li>Projector displaying Unity\u2019s matrix world + reactive avatar  </li> <li>Depth-sensing camera mounted front-left or centered  </li> <li>Optional Roland V-1HD for blending camera + Unity output  </li> </ul> <p>Placeholder for installation diagram [INSERT: Floor plan with speaker positions + projector location]</p>"},{"location":"final-installation/#space-requirements","title":"Space Requirements","text":"<ul> <li>Medium-large room (20\u201330 ft), open industrial layout  </li> <li>Dim lighting to enhance projection contrast  </li> <li>Sufficient distance between audience and projection wall for safety  </li> <li>Enough circulation room for multiple users to move freely  </li> </ul>"},{"location":"final-installation/#user-journey","title":"User Journey","text":""},{"location":"final-installation/#1-arrival","title":"1. Arrival","text":"<p>Visitors walk into a dim room illuminated by the matrix projection and a pulsing humanoid figure.</p> <p>Placeholder for arrival scene photo [INSERT: Photo of projection wall on entry]</p>"},{"location":"final-installation/#2-onboarding","title":"2. Onboarding","text":"<p>A facilitator briefly explains: - How to use the trackball - How movement affects the system - What to expect sonically and visually  </p>"},{"location":"final-installation/#3-interaction","title":"3. Interaction","text":"<ul> <li>Users spatialize stems using the Nulea M512 trackball  </li> <li>Their movement affects tempo and visual reactivity  </li> <li>The installation cycles through stem sets across the evening  </li> </ul>"},{"location":"final-installation/#4-ending-reset","title":"4. Ending / Reset","text":"<p>After a period of inactivity, the system returns to a calm, default loop until the next participant engages.</p>"},{"location":"final-installation/#visual-sonic-design","title":"Visual &amp; Sonic Design","text":""},{"location":"final-installation/#visuals","title":"Visuals","text":"<ul> <li>Matrix-inspired shader grid  </li> <li>HSV ramping effects tied to sound regions  </li> <li>Stylized humanoid figure pulsing with data streams  </li> </ul>"},{"location":"final-installation/#sound","title":"Sound","text":"<ul> <li>8 musical sets \u00d7 4 stems  </li> <li>IEM spatialization via Reaper  </li> <li>Subtle tempo changes based on group movement  </li> </ul> <p>Placeholder for audio-reactive screenshot [INSERT: Unity screenshot showing reactive matrix shader]</p>"},{"location":"final-installation/#accessibility-inclusivity","title":"Accessibility &amp; Inclusivity","text":"<ul> <li>Open floor plan with no required reach constraints  </li> <li>Trackball mouse usable while seated or standing  </li> <li>Visual indicators support those with reduced hearing  </li> <li>Moderate levels ensure safe auditory exposure  </li> </ul>"},{"location":"final-installation/#documentation-media","title":"Documentation Media","text":"<ul> <li>[INSERT: Installation photos] </li> <li>[INSERT: Short demo video] </li> <li>[INSERT: Diagram of data flow or speaker layout]</li> </ul>"},{"location":"final-installation/#reflection","title":"Reflection","text":""},{"location":"final-installation/#what-worked-well","title":"What Worked Well","text":"<ul> <li>Strong coherence between visuals, sound, and interaction  </li> <li>Trackball panning felt intuitive and engaging  </li> <li>Spatial system adapted well to the unique architecture of Underground Atlanta  </li> </ul>"},{"location":"final-installation/#challenges","title":"Challenges","text":"<ul> <li>Variability in crowd detection required filtering  </li> <li>Latency occasionally varied depending on machine load  </li> <li>Some projection alignment challenges in an industrial space  </li> </ul>"},{"location":"final-installation/#future-improvements","title":"Future Improvements","text":"<ul> <li>Expand gesture classification (MediaPipe, OpenCV)  </li> <li>Smoother transitions between musical scenes  </li> <li>Fully portable version using standalone Unity builds and integrated audio processing  </li> </ul> <p>Placeholder for post-event photo [INSERT: Group photo or final setup shot]</p>"},{"location":"tech-details/","title":"Tech Details","text":""},{"location":"tech-details/#tech-details","title":"Tech Details","text":""},{"location":"tech-details/#hardware","title":"Hardware","text":"<ul> <li>MacBook Pro 14\" (Apple Silicon), main control computer running Ableton Live 12, Unity + OSC routing to Reaper  </li> <li>Midas M32, used as both the audio interface and multichannel mixer  </li> <li>Neumann KH 120, primary spatial speakers (head-level arc and front overhead)  </li> <li>QSC K10.2, floor-level reinforcement  </li> <li>Alto Professional TS18C Subwoofer, low-end reinforcement  </li> <li>Projector, front-wall visuals (model varies) </li> <li>Roland V-1HD Video Mixer, blends camera feed and OpenCV output with Unity projections  </li> <li>Intel RealSense D455f Depth Camera, crowd tracking and centroid estimation  </li> <li>Nulea M512 Wireless Trackball Mouse, spatial-panning controller  </li> </ul>"},{"location":"tech-details/#software","title":"Software","text":"<ul> <li>Unity, visual environment, shader system, OSC output  </li> <li>Ableton Live, 8-scene stem engine  </li> <li>Reaper, IEM spatial audio processing  </li> </ul>"},{"location":"tech-details/#software-icons","title":"Software Icons","text":""},{"location":"tech-details/#libraries-plugins","title":"Libraries / Plugins","text":"<ul> <li>IEM Ambisonics Suite (Object-Based Panner, Scene Rotator, In-Ear, etc.)  </li> <li>#extOSC \u2013 Open Sound Control, system-wide OSC routing  </li> <li>OpenCV, depth tracking and centroid extraction  </li> </ul>"},{"location":"tech-details/#libraries-graphic","title":"Libraries Graphic","text":""},{"location":"tech-details/#real-time-matrix-vfx","title":"Real-Time Matrix VFX","text":"<p>MatrixVFX</p> <p> </p>"},{"location":"tech-details/#system-diagram-data-flow","title":"System Diagram / Data Flow","text":""},{"location":"tech-details/#interaction-design","title":"Interaction Design","text":""},{"location":"tech-details/#user-actions","title":"User Actions","text":"<ul> <li>Move through physical space  </li> <li>Use the Nulea trackball to spatialize stems  </li> <li>Toggle stem groups and mirror modes  </li> <li>Observe visuals reacting to movement and input  </li> </ul>"},{"location":"tech-details/#system-responses","title":"System Responses","text":"<ul> <li>Real-time spatial changes  </li> <li>Matrix shader effects and avatar feedback  </li> <li>Tempo changes based on group clustering  </li> <li>Progression through eight stem sets  </li> </ul>"},{"location":"tech-details/#implementation-details","title":"Implementation Details","text":""},{"location":"tech-details/#unity","title":"Unity","text":"<ul> <li>Matrix shader environment  </li> <li>3D speaker-array visualization  </li> <li>Data-avatar representation  </li> <li>See Unity tab. </li> </ul>"},{"location":"tech-details/#reaper","title":"Reaper","text":"<ul> <li>Four routed tracks: Drums, Bass, Harmony, Melody </li> <li>IEM suite for spatialization  </li> <li>OSC parameter mapping  </li> </ul>"},{"location":"tech-details/#ableton","title":"Ableton","text":"<ul> <li>Eight musical scenes  </li> <li>Outputs four stems directly to Reaper  </li> <li>Receives tempo modulation from Unity  </li> </ul>"},{"location":"tech-details/#bpdistributionspy","title":"BPDistributions.py","text":"<ul> <li>see BPDistrubtion tab</li> </ul>"},{"location":"tech-details/#requirements-setup","title":"Requirements &amp; Setup","text":""},{"location":"tech-details/#software-needed","title":"Software Needed","text":"<ul> <li>Unity  </li> <li>Reaper + IEM plugins  </li> <li>Ableton Live  </li> <li>Python 3  </li> </ul>"},{"location":"tech-details/#hardware-connections","title":"Hardware Connections","text":"<ul> <li>M32 \u2192 all speakers  </li> <li>Projector \u2192 HDMI  </li> <li>RealSense camera \u2192 USB-C  </li> <li>Trackball \u2192 USB Dongle or Bluetooth</li> </ul>"},{"location":"tech-details/#running-the-system","title":"Running the System","text":"<ol> <li>Launch Reaper  </li> <li>Load Ableton stem sets  </li> <li>Open Unity scene  </li> <li>Confirm OSC routing  </li> <li>Begin interaction  </li> </ol>"},{"location":"unity/","title":"Unity","text":""},{"location":"unity/#unity-editor-demo","title":"Unity Editor Demo","text":"<p>MatrixVFX</p> <p></p>"}]}